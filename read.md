## üîπ Introduction to Microservices

### ‚ùì The Big Question

**Ever wonder how apps like Instagram, Netflix, or Amazon work smoothly with millions of users?**
It‚Äôs not one giant app‚Äîit‚Äôs a team of _small, independent services_ working together. That‚Äôs **microservices**.

---

## üèõÔ∏è Before Microservices: The Monolith

- Applications used to be built as **monoliths**.

  - Everything was packed into **one system**: UI, business logic, database access.

- Example: In an old-school e-commerce app:

  - User management, product catalog, payment, and order tracking all ran as **one big app**.

### üö® Problems with Monoliths

- **Scaling is hard**: You can't scale just one part, like payments. You must scale everything.
- **Fragile codebase**: A small change can break the whole app.
- **Team issues**: Developers working on different features can clash easily.

---

## üîß Enter Microservices

**Microservices = breaking the app into small, independent services**
Each one handles a **specific task**, like:

- üîê Authentication
- üõí Product catalog
- üí≥ Payments
- üì¶ Order tracking

### üõ† Benefits:

- **Scalability**: Scale what‚Äôs needed, not the whole app.
- **Fault isolation**: One service fails? The rest keep running.
- **Flexibility**: Use the best language or tech for each service.
- **Faster updates**: Teams can build and deploy services independently.

---

## üì° How Do Microservices Talk?

- **Lightweight protocols** like HTTP or message queues
- Each service is **independent**, can use **different tech stacks**

---

## üì¶ Packaging with Containers

- Microservices are often put into **containers** using **Docker**
- Containers are:

  - Portable üß≥
  - Consistent across environments ‚öôÔ∏è
  - Isolated üõ°Ô∏è

---

## üöÄ Managing Containers at Scale

- Use **Kubernetes** to:

  - Deploy
  - Scale
  - Monitor & manage containers

- Kubernetes helps manage **hundreds or thousands of microservices**

---

## ‚ö†Ô∏è Microservices Challenges

- How do services **communicate efficiently**?
- How do we **monitor** all services?
- How do we ensure **security** and **reliability**?

---

## üï∏Ô∏è Solution: Service Mesh

> A **service mesh** handles all that complexity.
> It simplifies communication, observability, and security across microservices.

---

### ‚úÖ Up Next: Intro to Service Mesh!

---

---

## üï∏Ô∏è What Is a Service Mesh (And Why It Matters)

### üåÜ Imagine This...

Microservices are like **a bustling city**:

- Each **building = a service**
- Each **road = communication path**

Without traffic signals or GPS? Total **chaos**.
That‚Äôs where a **service mesh** comes in ‚Äî it‚Äôs the **traffic system** for your microservices.

---

## üö¶ What a Service Mesh Does

A service mesh:

- **Manages how services communicate**
- Adds **proxies** (tiny helpers) to handle:

  - Traffic control
  - Security
  - Observability (monitoring)

These proxies sit **next to** your services ‚Äî like a **motorcycle sidecar** üèçÔ∏è
This is called a **sidecar configuration**.

---

## üß† How It Works

### üîπ Two Key Components:

1. **Control Plane** üß≠

   - Think of it as the **brain**.
   - Sets the rules: how services should talk.

2. **Data Plane** üì¶

   - Made of **proxies**.
   - They follow the rules and handle real-time traffic.

üí° These proxies ensure that communication is:

- Smooth ‚úÖ
- Secure üîí
- Reliable üì∂

---

## üÜï What‚Äôs Changing?

- New models like **Ambient Mesh** remove the sidecar model for more flexibility and performance.

---

## üß© Why Do We Need a Service Mesh?

### 1. **Traffic Management**

- Microservices = tons of communication paths.
- Like rush hour üöóüöïüöô on a highway ‚Äî requests can get:

  - Delayed
  - Lost
  - Bottlenecked

A service mesh helps **route traffic efficiently**.

---

### 2. **Security**

Without a service mesh:

- Every service must handle **its own security** (encryption, access rules).
- More services = more room for mistakes ‚ö†Ô∏è

With a service mesh:

- Security is **centralized and consistent** across all services.

---

### 3. **Observability**

- With a few services, tracking is easy.
- With **dozens or hundreds**, it‚Äôs like watching every street in a city üåÉ

A service mesh gives you **full visibility**:

- What's working
- What‚Äôs failing
- Where traffic is going

---

## üõ°Ô∏è Meet Istio

- Istio is one of the most popular service meshes.
- It **solves traffic, security, and visibility problems** for microservices.

---

### ‚ñ∂Ô∏è Coming Next: Deep Dive into **Istio**

---

## üöÄ Introducing Istio: The Game-Changer for Microservices

### üß† Recap:

We‚Äôve seen the chaos of microservices and how service meshes help ‚Äî now meet **Istio**, one of the **most popular service mesh tools** out there.

---

## üß∞ What Is Istio?

- üß© **Open-source** service mesh
- üîê Connects, secures, and monitors your services
- üö´ No need to **rewrite your code** ‚Äî just plug and go!

---

## üí° Why Istio Stands Out

### üîí 1. **Secure Communication**

- Encrypts traffic between services
- Uses **authentication + encryption**
- Think of it like every service having its **own lock and key**

---

### ‚öñÔ∏è 2. **Automatic Load Balancing**

- Prevents any one service from getting overwhelmed
- Keeps your system **smooth and responsive**

---

### üß≠ 3. **Traffic Control**

- Fine-grained control over:

  - Routing
  - Retries on failed requests
  - A/B testing or traffic splitting

---

### üëÅÔ∏è 4. **Observability**

- Deep insights via:

  - Logs
  - Metrics
  - Distributed Tracing

- Makes it easy to **spot and fix issues fast**

---

## üõ†Ô∏è Istio Architecture: How It Works

### 1. **Data Plane** üõ∞Ô∏è (Where the traffic flows)

- Powered by **Envoy proxies**
- Handles:

  - Routing
  - Load balancing
  - Encryption
  - Resilience (retries, timeouts)

üì¶ Envoy = the **messenger** carrying your service traffic safely.

---

### 2. **Control Plane** üéÆ (Where decisions are made)

- Managed by **Istiod**
- Configures Envoy proxies
- Sets:

  - Traffic rules
  - Security policies
  - Service discovery (who talks to who)

üß† Istiod = the **brain** behind the traffic system.

---

## ‚öôÔ∏è Deployment Options in Istio

### 1. **Sidecar Mode** üèçÔ∏è

- Envoy runs **next to each service**
- Acts like a **personal assistant** for traffic
- Handles everything: routing, security, etc.

---

### 2. **Ambient Mode** ‚òÅÔ∏è

- Newer, **lightweight model**
- One proxy per **node**, optionally per **namespace**
- Great for **large-scale** setups ‚Äî reduces overhead

---

---

## üß≠ Istio Data Plane Modes: Sidecar vs Ambient

Istio offers **two primary data plane modes** to manage traffic between services:

### 1. **Sidecar Mode**

- **Architecture**: Each pod in your Kubernetes cluster has its **own Envoy proxy sidecar**.
- **Responsibilities**: Handles **routing, security, and monitoring** from **Layer 4 to Layer 7**.
- **Benefits**:

  - Each pod has **its own identity** and **encryption**.
  - Fine-grained **traffic management** and **observability**.
  - Like giving each pod its **own bodyguard**.

- **Drawbacks**:

  - High **resource usage** (CPU & memory), especially in large clusters.
  - Operational overhead for **upgrades and restarts**.

---

### 2. **Ambient Mode** _(Newer, more efficient)_

- **Architecture**:

  - **No sidecars** in pods.
  - Uses two layers:

    - **Secure Overlay Layer**: Managed by `ztunnel`, a lightweight data plane running on **each node**, providing **zero-trust security** and encrypted connections.
    - **L7 Processing Layer**: Uses **waypoint proxies** for advanced Layer 7 features (e.g., traffic splitting, fault injection).

- **Benefits**:

  - Lower **memory/CPU usage**.
  - **Simplifies updates** (no pod restarts).
  - **Flexible**: Start with basic security and **add features as needed**.

- **Drawbacks**:

  - Still **relatively new**; some advanced features may require **manual config**.

---

> ‚úÖ **Key Insight**: Ambient mode **decouples** security and traffic management responsibilities, making deployments more **resource-efficient and flexible**.

---

### ‚ñ∂Ô∏è Up Next: A Closer Look at Sidecar and Ambient Modes

---

## ‚öôÔ∏è Setting Up the Environment for Istio

### üéØ Goal:

Prepare your local machine to **install and run Istio** using Minikube, Kubectl, and Helm.

---

## üß± Prerequisites

| Tool         | Purpose                                    |
| ------------ | ------------------------------------------ |
| **Minikube** | Local Kubernetes cluster for testing & dev |
| **kubectl**  | CLI to interact with your K8s cluster      |
| **Helm**     | Package manager for Kubernetes             |

---

## üíª System Requirements

- üß† **CPU**: Minimum 2 cores (Recommended: 6 cores)
- üíæ **Memory**: At least 8 GB RAM (Recommended: 7+ GB for cluster)
- üíΩ **Disk**: 20 GB free
- ‚öôÔ∏è **Kubernetes** version: 1.28 ‚Äì 1.31

---

## üõ†Ô∏è Step-by-Step Tool Installation

### 1. **Install Minikube**

- ‚úÖ Visit [Minikube Docs](https://minikube.sigs.k8s.io/docs/start/)
- üì¶ On macOS? Use **Homebrew**:

  ```bash
  brew install minikube
  ```

- üîç Verify installation:

  ```bash
  minikube version
  ```

---

### 2. **Install kubectl**

- ‚úÖ Visit [kubectl Docs](https://kubernetes.io/docs/tasks/tools/)
- üì¶ For macOS:

  ```bash
  brew install kubectl
  ```

- üîç Verify:

  ```bash
  kubectl version --client
  ```

---

### 3. **Install Helm**

- ‚úÖ Visit [Helm Docs](https://helm.sh/docs/intro/install/)
- üì¶ For macOS:

  ```bash
  brew install helm
  ```

- üîç Verify:

  ```bash
  helm version
  ```

### 3. **Install Stern**

- ‚úÖ Visit [Stern Docs](https://helm.sh/docs/intro/install/)
- üì¶ For macOS:

  ```bash
  brew install stern
  ```

- üîç Verify:

  ```bash
  stern version
  ```

  brew install stern

---

## üöÄ Start Your Local Kubernetes Cluster

### Run Minikube:

```bash
minikube start --profile=istio-demo --cpus=2 --memory=3072
```

- Creates a Minikube cluster named `istio-demo`
- Assigns 2 CPUs and \~3GB RAM
  _You can reduce resources if needed, but ensure Istio has enough to operate._

---

### üîç Confirm Cluster Is Running:

```bash
kubectl cluster-info
```

You should see:

- Control plane IP
- CoreDNS service status
  ‚úÖ This confirms your cluster is ready!

---

## üéâ Summary

By the end of this setup:

- ‚úÖ **Minikube** is running locally
- ‚úÖ You have **kubectl** and **Helm** ready
- ‚úÖ Kubernetes cluster is live and verified

---

### ‚è≠Ô∏è Next Up:

We‚Äôll **download Istio** and **install it using Helm in Ambient mode**.

---

## üì¶ Installing Istio with Helm

### üõ†Ô∏è Installation Method

We‚Äôre using **Helm** ‚Äî a reliable and flexible package manager for Kubernetes ‚Äî to install **Istio in ambient mode**.

---

## üß≠ Pre-Installation Checklist

- ‚úÖ Minikube up and running
- ‚úÖ kubectl and Helm installed
- ‚úÖ Kubernetes version between 1.28 ‚Äì 1.31
- ‚úÖ Environment-specific prerequisites reviewed (check [Istio Docs](https://istio.io/latest/docs/setup/platform-setup/))

---

## üöÄ Step-by-Step Installation

### 1. **Add Istio Helm Repository**

```bash
helm repo add istio https://istio-release.storage.googleapis.com/charts
helm repo update
```

- Adds the official Istio Helm chart repo.
- Fetches the latest versions.

---

### 2. **Download Istio CLI Tools (Optional but Recommended)**

```bash
curl -L https://istio.io/downloadIstio | sh -
cd istio-*
cd bin
export PATH=$PWD/bin:$PATH
```

- Gives you access to `istioctl` and sample configs.
- Make `istioctl` available globally.

---

### 3. **Install Istio Base**

```bash
helm install istio-base istio/base -n istio-system --create-namespace --set defaultRevision=default --wait
```

- Installs **CRDs** and sets up **RBAC permissions**.
- All Istio components will live in the `istio-system` namespace.

---

### 4. **Install Gateway API CRDs**

This will install Istiod If not found:

```bash
kubectl get crd gateways.gateway.networking.k8s.io &> /dev/null || kubectl apply -f https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.0.0/standard-install.yaml

```

- Required for managing traffic via Istio Gateway.

---

### 5. **Install istiod (Control Plane)**

```bash
helm install istiod istio/istiod -n istio-system --set profile=ambient --wait
```

- `istiod` is the **brain** of the mesh ‚Äî handles configuration, service discovery, policies.

---

### 6. **Install Istio CNI**

```bash
helm install istio-cni istio/cni -n istio-system --set profile=ambient --wait
```

- Sets up **CNI plugin** for ambient mode.
- Ensures smooth traffic redirection without sidecars.

---

### 7. **Install ztunnel (Data Plane for Ambient Mode)**

```bash
helm install ztunnel istio/ztunnel -n istio-system --wait
```

- ztunnel manages secure traffic between pods.
- No sidecars needed ‚Äî uses a DaemonSet.

---

### 8. **Install Ingress Gateway**

```bash
helm install istio-ingressgateway istio/gateway -n istio-ingress --create-namespace
```

- Enables **external access** to services in the mesh.

### **Install Istioctl**

```bash
curl -sL https://istio.io/downloadIstioctl | sh -
export PATH=$HOME/.istioctl/bin:$PATH

```

---

## üß™ Verify Installation

```bash
helm list -n istio-system
kubectl get pods -n istio-system
```

You should see:

- `istiod`
- `ztunnel`
- `istio-cni`
- All in **Running** or **Completed** state

---

## ‚úÖ Summary

You‚Äôve successfully installed:

- üß† **Istio Control Plane** (`istiod`)
- üîå **CNI Plugin** and **ztunnel** for the ambient data plane
- üåê **Ingress Gateway** for exposing services

---

### ‚è≠Ô∏è Next Up:

We‚Äôll **deploy a sample app** and **add it to the ambient mesh** to demonstrate Istio‚Äôs capabilities in action.

## üìö Istio Bookinfo Sample Application

### üîß What is Bookinfo?

- A **mock e-commerce app** used to showcase **Istio features**.
- Composed of **multiple microservices**, each written in a **different language**, to simulate real-world environments.

### üì¶ Microservice Architecture:

| Service       | Responsibility                                       |
| ------------- | ---------------------------------------------------- |
| `productpage` | Entry point; retrieves book info from other services |
| `details`     | Provides book description and author info            |
| `reviews`     | Displays customer reviews; calls `ratings`           |
| `ratings`     | Provides star ratings; called by `reviews`           |

---

### üóÇÔ∏è Kubernetes Resources (from `bookinfo.yaml`)

- **Services**: Route traffic to each microservice (e.g., `reviews` on port 9080).
- **Deployments**: Define how microservices are run, including multiple versions.
- **ServiceAccounts**: Assign pod identities to enable secure communication within the cluster.

---

### üåê Ingress Configuration (from `bookinfo-gateway.yaml`)

- **Gateway Resource**:

  - Defines how **external traffic** enters the **service mesh**.
  - Uses a **selector** to bind to the Istio Ingress Gateway.

- **VirtualService Resource**:

  - Manages **internal routing** once traffic enters the mesh.
  - Defines how traffic is directed to the appropriate microservice.

---

### üõ†Ô∏è Deployment Steps

1. **Create Namespace**:

   ```bash
   kubectl create namespace bookinfo
   ```

2. **Deploy Application**:

   ```bash
   kubectl apply -f k8s/bookinfo.yaml -n bookinfo
   ```

3. **Verify Pod Status**:

   ```bash
   kubectl get pods -n bookinfo
   ```

   4. **Apply Gateway + VirtualService**:

   ```bash
   kubectl apply -f k8s/bookinfo-gateway.yaml -n bookinfo
   ```

4. **Expose App via Ingress Gateway**:

   - Confirm the gateway:

     ```bash
     kubectl get svc istio-ingressgateway -n istio-ingress
     ```

   - If using **Minikube**, run tunnel in a new terminal:

     ```bash
     minikube profile list

     minikube tunnel -p istio-demo
     ```

   - Recheck external IP:

     ```bash
     kubectl get svc istio-ingressgateway -n istio-ingress
     ```

5. **Test Access**:

   - Curl:

     ```bash
     curl http://localhost/productpage
     ```

   - Or open in browser:

     ```
     http://localhost/productpage
     ```

> üåÄ You'll observe the `reviews` section randomly rotating between different versions (v1, v2). This demonstrates Istio's traffic distribution capabilities.

---

### üìà Next Steps

- Add the application to the **service mesh**
- Generate traffic
- **Visualize and secure** communication with **Kiali**

### üîê **Add App to Ambient Mesh with Mutual TLS**

The label istio.io/dataplane-mode=ambient enables Istio Ambient Mesh for the namespace, allowing workloads to join the service mesh without sidecar injection, using zTunnel and optional Waypoint proxies for secure, efficient traffic management

- Label namespace to join mesh:

  ```bash
  kubectl label namespace bookinfo istio.io/dataplane-mode=ambient
  ```

- ‚úÖ No pod restarts required. mTLS is automatically enabled.

---

### 7. üìä **Visualize Traffic with Prometheus + Kiali**

for we to visualize we need to Install Istio Observability Add-ons

```bash
mkdir -p istio-addons
curl -L https://raw.githubusercontent.com/istio/istio/release-1.25/samples/addons/prometheus.yaml -o istio-addons/prometheus.yaml
curl -L https://raw.githubusercontent.com/istio/istio/release-1.25/samples/addons/grafana.yaml -o istio-addons/grafana.yaml
curl -L https://raw.githubusercontent.com/istio/istio/release-1.25/samples/addons/kiali.yaml -o istio-addons/kiali.yaml
curl -L https://raw.githubusercontent.com/istio/istio/release-1.25/samples/addons/jaeger.yaml -o istio-addons/jaeger.yaml

kubectl apply -f k8s/istio-addons/ -n istio-system
```

To confirm pods

```bash
kubectl get svc -n istio-system
```

To open kiali dashboard:

```bash
istioctl dashboard kiali

#or get svc of kiali and portforward

kubectl get svc -n istio-system
kubectl port-forward svc/kiali -n istio-system 20001:20001

```

# Istio Observability Configuration Guide

## Problem Analysis

The default istio-addons setup fails because it lacks proper service integration configurations, while the working observability setup has complete service connections.

### Main Issues with Default istio-addons:

1. **Missing Grafana Configuration in Kiali** - "grafana URL is not set in Kiali configuration"
2. **Prometheus Connection Issues** - Cannot connect to `http://prometheus.istio-system:9090`
3. **Missing External Services Configuration** - No proper service discovery setup
4. **Missing Dashboard ConfigMaps** - No Istio-specific dashboards

## Required Changes

### 1. Fix Kiali Configuration

**ADD to istio-addons/kiali.yaml:**

```yaml
external_services:
  custom_dashboards:
    enabled: true
  grafana:
    enabled: true
    in_cluster_url: 'http://grafana.istio-system:3000'
    url: 'http://grafana.istio-system:3000'
  istio:
    root_namespace: istio-system
  prometheus:
    url: 'http://prometheus.istio-system:9090'
  tracing:
    enabled: false
```

**REPLACE the existing:**

```yaml
external_services:
  custom_dashboards:
    enabled: true
  istio:
    root_namespace: istio-system
  tracing:
    enabled: false
```

### 2. Apply the Fixed Configuration

````bash
# Apply the updated configuration

# 1Ô∏è‚É£ Apply the updated configuration (e.g., updated URLs, Prometheus endpoints)
kubectl apply -f istio-addons/kiali.yaml

# 2Ô∏è‚É£ Restart the deployment to pick up changes (some changes won't apply until restart)
kubectl rollout restart deployment/kiali -n istio-system

# 3Ô∏è‚É£ Watch rollout status live until it's fully rolled out
kubectl rollout status deployment/kiali -n istio-system --watch



---

<!-- ## Phase 3: Verify the Fix

### TThis updates the Kiali Deployment, ensures any changes are reloaded into the Kiali pod.

### 1. Check All Services are Running

```bash
kubectl get pods -n istio-system | grep -E "(kiali|prometheus|grafana|jaeger)"
kubectl get svc -n istio-system | grep -E "(kiali|prometheus|grafana|jaeger)"
``` -->

### 2. Test Kiali Dashboard

```bash
istioctl dashboard kiali
````

**Expected Results:**

- ‚úÖ No "grafana URL is not set" error
- ‚úÖ Prometheus metrics loading successfully
- ‚úÖ Service mesh visualization working
- ‚úÖ Health status showing correctly

### 3. Test All Dashboards

```bash
# Test each dashboard
istioctl dashboard kiali
istioctl dashboard grafana
istioctl dashboard jaeger
istioctl dashboard prometheus
```

# Now lets simluate traffic and review on kiali

Open new terminal and simulate traffic :

```bash

for i in $(seq 1 100); do
curl -s http://localhost/productpage
done



```

now refresh kiali dashboard to see the traffic:

<!-- ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE
ALMOST THERE -->

### üîê **Visualizing and Securing Traffic in Istio with Kiali and ztunnel (Ambient Mode)**

After deploying the **Bookinfo application** and configuring routing via the **Istio Ingress Gateway**, we can now visualize and secure traffic using **Kiali**.

#### üîé Traffic Graph in Kiali

- Navigate to the **Traffic Graph** section in Kiali.
- You'll see how the `productpage` receives traffic through the **Ingress Gateway**, then fans out requests to `reviews`, `details`, and `ratings`.
- This graph provides real-time visibility into service interactions and routing paths within the mesh.

#### üîê Confirming Mutual TLS (mTLS)

- In the Kiali UI, switch to the **Security** view.
- You'll notice **padlock icons** between services ‚Äî this confirms **mutual TLS** is active.
- Click on the connections to verify: it should show **‚ÄúmTLS Enabled.‚Äù**

#### üîß How Ambient Mode (ztunnel) Secures Traffic

- Istio **ztunnel** is the lightweight data plane component in Ambient Mode.
- It handles all **secure traffic** (L4 routing and encryption) **without sidecar proxies**.

To verify ztunnel activity:

### üîí 6. **Verify Mutual TLS**

- In **Kiali**, navigate to:

  ```
  Graph > Click on an edge or service > Security tab
  ```

- Confirm padlocks (üîí) and **mTLS enabled** status.

---

### üîé 7. **Inspect Traffic via zTunnel**

- View zTunnel logs:

  ```bash
  kubectl get pods -n istio-system
  stern ztunnel -n <z-tunnel-pod>
  ```

---

## üß† Key Concepts Highlighted

| Concept               | Explanation                                                                 |
| --------------------- | --------------------------------------------------------------------------- |
| **Ambient Mesh**      | Istio mode with sidecarless data plane (zTunnel) for simplified operations. |
| **mTLS (Mutual TLS)** | Encrypts service-to-service traffic inside the mesh.                        |
| **Kiali**             | Istio‚Äôs UI for visualizing mesh topology and real-time traffic.             |
| **zTunnel**           | Handles transparent, secure traffic routing without sidecars.               |

---

---

## üîê Verifying Mutual TLS (mTLS) in Istio Ambient Mesh

Once your workloads are part of the mesh, it‚Äôs crucial to **validate that mTLS is actively securing communication**. Below are **four ways to confirm** it:

---

### ‚úÖ **1. Use `istioctl ztunnel-config workloads`**

This command confirms that **HBONE** (HTTP/2-based overlay network protocol used in ambient mesh with mTLS) is active.

```bash
istioctl ztunnel-config workloads
```

- Look for the `HBONE` protocol listed under workloads in the `bookinfo` namespace.
- ‚ö†Ô∏è **Note**: Seeing `HBONE` indicates secure routing is possible, but it does **not block plaintext traffic**. To enforce strict encryption, you must configure:

  ```yaml
  PeerAuthentication:
    mtls:
      mode: STRICT
  ```

---

### üìä **2. Check Prometheus Metrics**

**Prometheus Metric**: `istio_tcp_connections_opened_total`

- Open **Prometheus Dashboard**
- Go to **Graph** section.
- Enter the following query:

  ```text
  istio_tcp_connections_opened_total
  ```

- Click **Execute**.
- Look for the label:

  ```
  connection_security_policy = "mutual_tls"
  ```

‚úÖ This confirms that mTLS is actively used for open TCP connections.

---

### üìà **3. Inspect the Kiali Dashboard**

1. Open Kiali:

   ```bash
   istioctl dashboard kiali
   ```

2. Go to **Traffic Graph**.
3. Make sure you‚Äôre generating traffic:

   ```bash
   while true; do curl -s http://localhost/productpage > /dev/null; sleep 1; done
   ```

4. **Look for üîí padlocks between services**.
5. Click on a connection line ‚Üí go to **Security** tab:

   - Confirm **mTLS Enabled**.
   - Under **Principals**, you‚Äôll see **SPIFFE IDs**, e.g.:

     ```
     spiffe://cluster.local/ns/bookinfo/sa/productpage
     ```

‚ÑπÔ∏è **SPIFFE ID** is a unique identity (like a digital passport) used by Istio to securely authenticate services.

---

### üìã **4. Check Logs in the `ztunnel` Pod**

1. Get the zTunnel pod:

   ```bash
   kubectl get pods -n istio-system | grep ztunnel
   ```

2. View logs using `stern` or `kubectl logs`:

   ```bash
   stern ztunnel -n istio-system
   # or
   kubectl logs <ztunnel-pod-name> -n istio-system
   ```

3. In logs, look for:

   - `src.identity`: Source SPIFFE ID
   - `dst.identity`: Destination SPIFFE ID

‚úÖ This confirms **secure identity-based routing using mTLS**.

---

## üß† Summary Table

| Method                     | Tool Used     | What to Look For                              |
| -------------------------- | ------------- | --------------------------------------------- |
| `ztunnel-config workloads` | `istioctl`    | `HBONE` protocol listed                       |
| Prometheus Metric          | Prometheus UI | `connection_security_policy=mutual_tls`       |
| Kiali Dashboard            | Kiali         | üîí padlocks + SPIFFE IDs under Security       |
| zTunnel Logs               | stern/logs    | `src.identity` and `dst.identity` with SPIFFE |

---

######

######

---

## üö¶ **How Istio Ensures Smooth Traffic Flow in Microservices**

Modern microservice architectures involve **dozens or hundreds of services** talking to each other. Without proper coordination, this can lead to **delays, bottlenecks, or outright failure**. That‚Äôs where **Istio** comes in ‚Äî acting like a **traffic controller** for your app‚Äôs internal communication.

---

### üß≠ **Istio = Smart Traffic Controller**

Think of your microservices as cars in a busy city. Just like traffic lights and signs prevent chaos, **Istio intelligently directs service traffic**, ensuring:

- ‚úÖ Secure communication
- ‚úÖ Balanced traffic distribution
- ‚úÖ Resilience to failure
- ‚úÖ Controlled feature rollouts

---

### üõ£Ô∏è **How Istio Directs Traffic**

1. **Service Registry**:

   - Istio automatically discovers services via Kubernetes‚Äô internal registry.
   - For **external services**, you can define **ServiceEntry** resources.

2. **Ztunnel (L4 traffic handler)**:

   - Runs on **every Kubernetes node**
   - Handles **Layer 4 (TCP)** traffic
   - Encrypts and forwards requests securely inside the mesh.

3. **Waypoint Proxy (L7 traffic handler)**:

   - Manages **Layer 7 (HTTP)** traffic for advanced logic:

     - Load balancing
     - Request retries
     - Circuit breaking
     - Fault injection
     - Header-based routing

4. **Istio Gateways**:

   - Handle **incoming/outgoing traffic** from outside your mesh.

---

### üß∞ **Key Traffic Management Features in Istio**

| Feature                | Purpose                                                                                              |
| ---------------------- | ---------------------------------------------------------------------------------------------------- |
| **VirtualService**     | Defines **how traffic is routed** to a service (e.g., canary, A/B tests).                            |
| **DestinationRule**    | Sets **policies** like load balancing and connection settings **after traffic reaches the service**. |
| **Fault Injection**    | Simulates service failures to test **resilience** and fallback behavior.                             |
| **Retries & Timeouts** | Automatically retries failed requests or times out after delays.                                     |
| **Circuit Breaking**   | Prevents **overloading** a service by temporarily blocking traffic when it's unhealthy.              |
| **A/B Testing**        | Sends new features to a **subset of users** before full rollout.                                     |

---

### üìå In Summary

Istio ensures **smooth, secure, and intelligent traffic flow** through:

- Auto-discovery via service registry
- Encrypted routing with `ztunnel`
- Advanced traffic logic with **waypoint proxies**
- Policies defined through custom Istio resources

In the upcoming videos or docs, you‚Äôll get hands-on with:

- Routing rules
- Failover strategies
- Load balancing setups
- Resilience testing through fault injection and circuit breaking

---

---

## üö¶ **Istio Virtual Services: Smart Routing for Microservices**

### üß† **What Is a Virtual Service in Istio?**

A **VirtualService** in Istio lets you **define how requests are routed** to a service ‚Äî like a **traffic controller** for your app's network.

Think of your app like a **busy city** and virtual services as the **intelligent, programmable map** telling each request where to go ‚Äî dynamically, and with rules you define.

---

### üéØ **Why Virtual Services Are Powerful**

Virtual services allow you to create **custom traffic routing rules** based on:

| Routing Criteria | Example Use Case                                    |
| ---------------- | --------------------------------------------------- |
| **HTTP headers** | Route based on a user's identity (`end-user: JSON`) |
| **Request path** | Route `/v2/orders` to a specific version            |
| **HTTP methods** | Send `GET` and `POST` to different destinations     |
| **Port numbers** | Target traffic through specific ports               |

---

### üìÑ **Example VirtualService YAML**

Here‚Äôs a simple breakdown of a virtual service YAML file used in the BookInfo app:

```yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: reviews-route
spec:
  hosts:
    - reviews
  http:
    - match:
        - headers:
            end-user:
              exact: jason
      route:
        - destination:
            host: reviews
            subset: v2
    - route:
        - destination:
            host: reviews
            subset: v3
```

üß© **What's `subset`?**
this is the review service, if user = jason, return v2 else return v3
It refers to a **specific version** of the service (like `v2`, `v3`) ‚Äî defined in the corresponding `DestinationRule`.

---

### ‚öñÔ∏è **Weighted Routing (A/B Testing or Canary Releases)**

You can split traffic between versions **gradually**:

```yaml
route:
  - destination:
      host: reviews
      subset: v1
    weight: 75
  - destination:
      host: reviews
      subset: v2
    weight: 25
```

üîß Total weight must always equal **100%**.

<!-- ---

### üõ†Ô∏è **Routing by URL Prefix**

You can match and route traffic based on the URL path:

```yaml
match:
  - uri:
      prefix: '/content/reviews'
```

This allows fine-grained control over what endpoints route to which services.

---

### üí° **Pro Tip for Host Naming**

- `host: reviews` ‚Üí Istio auto-expands this to `reviews.<namespace>.svc.cluster.local`
- ‚úÖ **Best practice**: Use the full FQDN (`reviews.bookinfo.svc.cluster.local`) to **avoid namespace-related issues**.

---

### üîÑ **What Happens After Routing?**

Once traffic reaches its destination, **DestinationRules** take over to:

- Apply **load balancing**
- Handle **retries and timeouts**
- Perform **circuit breaking**

> These will be covered in the next section.

---

--- -->

## üõ£Ô∏è **Istio Destination Rules: Managing Traffic After It Arrives**

### üö• **What Are Destination Rules?**

If **VirtualServices** guide traffic to the correct **destination**, then **DestinationRules** define **what happens to that traffic when it gets there** ‚Äî like **traffic laws inside a city**.

---

### üîÑ **Why Are Destination Rules Important?**

They:

- Define **subsets** (e.g., versioned deployments like `v1`, `v2`) based on pod labels
- Apply **traffic policies** like load balancing, TLS, and circuit breaking

---

### üß© **How Subsets Work (Versioning Magic)**

1. **Pods** in your Kubernetes `Deployment` have labels:

   ```yaml
   labels:
     app: reviews
     version: v2
   ```

2. **DestinationRule** defines subsets using those labels:

   ```yaml
   subsets:
     - name: v1
       labels:
         version: v1
     - name: v2
       labels:
         version: v2
   ```

3. Then, **VirtualService** can route traffic like:

   ```yaml
   route:
     - destination:
         host: reviews
         subset: v1
   ```

‚úÖ This allows Istio to route traffic **based on specific versions** of your service.

---

### ‚öôÔ∏è **Traffic Policies in Destination Rules**

Destination rules allow you to define how traffic behaves once it reaches the destination via:

| Feature              | Description                                                               |
| -------------------- | ------------------------------------------------------------------------- |
| **Load Balancing**   | Controls how requests are distributed among pods                          |
| **TLS Policies**     | Secures traffic between services using mTLS                               |
| **Circuit Breaking** | Prevents services from being overwhelmed by high traffic or failure rates |

---

### ‚öñÔ∏è **Load Balancing Strategies in Istio**

| Strategy                    | Description                                                                 |
| --------------------------- | --------------------------------------------------------------------------- |
| **Least Request** (default) | Sends traffic to the pod with the **fewest active requests**                |
| **Random**                  | Sends traffic to a **random** pod                                           |
| **Round Robin**             | Cycles through all pods **in order**                                        |
| **Weighted**                | Manually control traffic percentage to each version (used in A/B or canary) |

---

### üìÑ **Example DestinationRule with Subsets and Load Balancing**

```yaml
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: ratings-destination
spec:
  host: ratings
  subsets:
    - name: v1
      labels:
        version: v1
    - name: v3
      labels:
        version: v3
      trafficPolicy:
        loadBalancer:
          simple: ROUND_ROBIN
  trafficPolicy:
    loadBalancer:
      simple: LEAST_REQUEST
```

### üîç Explanation:

- All traffic to `ratings` defaults to **least request**.
- Traffic to **subset `v3`** uses **round robin** instead.

---

### üîê **Bonus: Add TLS and Circuit Breaking**

You can enhance security and resilience like so:

```yaml
trafficPolicy:
  tls:
    mode: ISTIO_MUTUAL
  connectionPool:
    http:
      http1MaxPendingRequests: 100
      maxRequestsPerConnection: 10
  outlierDetection:
    consecutiveErrors: 5
    interval: 10s
    baseEjectionTime: 30s
```

---

### ‚úÖ **Recap**

- **DestinationRules** define **how traffic behaves** once it hits a service
- They enable **versioned routing**, **secure connections**, and **resilient load balancing**
- Complement **VirtualServices** which handle **how traffic gets to the service**

---

######

######

######

---

### üîπ **Ambient Mode & Waypoint Proxies in Istio**

- **Ambient Mode**: An Istio data plane mode that **eliminates the need for sidecars** per pod.
- **Waypoint Proxies**:

  - Envoy-based Layer 7 proxies used in **ambient mode**.
  - Handle traffic for **multiple services**, not per service.
  - Enable full **Layer 7 features**: HTTP routing, load balancing, fault injection.
  - Deployed only when Layer 7 features are needed (after `ztunnel` handles Layer 4).

Here's your flow **cleaned up and formatted** step-by-step for clarity, assuming you're working with Istio Ambient Mode and setting up a `Waypoint Proxy` + traffic rules:

---

### üß≠ **Ambient Setup & Traffic Rule Application**

#### ‚úÖ 1. Check which namespaces are in Ambient Mode:

```bash
kubectl get ns -L istio.io/dataplane-mode
```

---

#### ‚úÖ 2. Inspect the Waypoint YAML (for visibility)

```bash
cat waypoint.yaml
```

Ensure it looks like:

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: waypoint
  namespace: bookinfo
  labels:
    istio.io/waypoint-for: service
spec:
  gatewayClassName: istio-waypoint
  listeners:
    - name: mesh
      port: 15008
      protocol: HBONE
```

---

#### ‚úÖ 3. Apply the Waypoint Proxy:

```bash
kubectl apply -f k8s/waypoint.yaml -n bookinfo
```

---

#### ‚úÖ 4. Confirm the Waypoint is active:

```bash
kubectl get gateway -n bookinfo
```

Look for `PROGRAMMED: True` in the status.

---

#### ‚úÖ 5. Label the namespace to use the Waypoint:

```bash
kubectl label namespace bookinfo istio.io/use-waypoint=waypoint
```

---

#### ‚úÖ 6. Apply the **DestinationRule**:

```bash
kubectl apply -f destination-rule.yaml -n bookinfo
```

---

#### ‚úÖ 7. Apply the base **VirtualService** (routes all to v1):

```bash
kubectl apply -f k8s/virtual-service-all-v1.yaml -n bookinfo
```

---

<!-- Let me know if you want a command to **verify which services the Waypoint is managing** or how to simulate traffic from `Fortio`. -->

### üîπ **Traffic Routing with VirtualService & DestinationRule**

#### üß™ Round-Robin by Default

- Istio routes requests across different versions (v1, v2, v3) of a service using round-robin if no routing rules are defined.

#### üéØ **Routing All Traffic to v1**

1. **DestinationRule** defines subsets based on pod labels:

   ```yaml
   subsets:
     - name: v1
       labels:
         version: v1
     - name: v2
       labels:
         version: v2
     - name: v3
       labels:
         version: v3
   ```

2. **VirtualService** routes traffic to subset v1:

   ```yaml
   route:
     - destination:
         host: reviews
         subset: v1
   ```

3. **Apply both configs**:

   ```bash
   kubectl apply -f k8s/destination-rule.yaml -n bookinfo
   kubectl apply -f k8s/virtual-service-all-v1.yaml -n bookinfo
   ```

4. **Validate in browser** or via **Kiali** (`localhost:20001/kiali`): only version 1 of reviews shows.

---

### üîπ **User-Based Traffic Routing**

#### üßç Jasmine sees v2, others see v1

- **Header-based routing using `end-user` HTTP header**.

- **VirtualService logic**:

  ```yaml
  - match:
      - headers:
          end-user:
            exact: jasmine
    route:
      - destination:
          host: reviews
          subset: v2
  - route:
      - destination:
          host: reviews
          subset: v1
  ```

- Apply config:

  ```bash
  kubectl apply -f k8s/virtual-service-reviews-v2-user.yaml -n bookinfo

  ### to confirm
  kubectl get virtualservices reviews -o yaml
  ```

- **Test** by logging in as different users:

  - `jasmine` ‚Üí sees **reviews v2** (with star ratings).
  - Others (e.g. `dave`) ‚Üí see **reviews v1**.

---

---

### üß≠ **What is Traffic Shifting in Istio?**

Traffic shifting lets you **gradually direct traffic** between different versions of a microservice. This is helpful for **canary releases** or **progressive rollouts**.

---

### üõ†Ô∏è **Core Concept: Weighted Routing**

Istio‚Äôs **VirtualService** uses **weights** to distribute traffic between service versions.

Example:

```yaml
http:
  - route:
      - destination:
          host: reviews
          subset: v1
        weight: 50
      - destination:
          host: reviews
          subset: v3
        weight: 50
```

- Weights must sum to **100**.

---

### üìÅ **Files Used**

1. **`virtual-service-all-v1.yaml`**

   - Routes 100% traffic to version 1 of all services.

2. **`virtual-service-reviews-50-v3.yaml`**

   - Routes 50% to `reviews:v1`, 50% to `reviews:v3`.

3. **`virtual-service-reviews-v3.yaml`**

   - Routes 100% to `reviews:v3` (no weights needed).

---

### üß™ **Steps Followed**

1. **Initial Setup:**

   ```bash
   kubectl apply -f k8s/virtual-service-all-v1.yaml
   ```

   - Confirms all traffic goes to `reviews:v1`.

2. **Start Traffic Shifting (50/50):**

   ```bash
   kubectl apply -f k8s/virtual-service-reviews-50-v3.yaml
   ```

   - Refreshing the app alternates between `v1` and `v3` views.

3. **Confirm in Kiali Dashboard:**

   - Generate traffic,

   ```bash
   for i in $(seq 1 100); do
   curl -s http://localhost/productpage
   done

   ```

   then go to service in kiali, reviews Shows traffic split (e.g., \~50% to each).

4. **Final Shift to 100% v3:**

   ```bash
   kubectl apply -f k8s/virtual-service-reviews-v3.yaml
   ```

   - All traffic now goes to `reviews:v3`.

---

### ‚úÖ **Outcome**

- **Progressive rollout** complete.
- Ensures stable deployment without downtime or risk to users.

---

## <!--

### üß™ Fault Injection with Istio: Simulate Failures Before They Happen

### üí• What is Fault Injection?

Fault injection is used to **simulate real-world failures** like:

- High latency (delays)
- Service crashes (HTTP 500s)
- Network issues

This helps **test the resilience** of your microservices and ensure graceful error handling.

---

firstly redirect all back to v1

```bash
 kubectl apply -f k8s/virtual-service-all-v1.yaml -n bookinfo

  kubectl apply -f k8s/virtual-service-all-v2.yaml -n bookinfo

```

### üîÅ Phase 1: **Inject Delay (15s) for Jasmine**

You simulate a **slow backend call** to the ratings service.

#### üß† Key Concepts:

- **VirtualService** resource
- `http.fault.delay.fixedDelay: 15s`
- `match.headers.end-user.exact: "jasmine"`

üìÅ Sample YAML:

```bash
 kubectl apply -f k8s/vs-delay-injection.yaml -n bookinfo
```

‚è± Result: Jasmine‚Äôs requests time out (`>6s`) while others are fine.

---

### ‚ùå Phase 2: **Simulate Failure (HTTP 500) for Jasmine**

You configure a virtual service to **abort requests**.

#### üß† Key Concepts:

- `http.fault.abort.httpStatus: 500`
- Again matched only for Jasmine

üìÅ Sample YAML:

```bash
 kubectl apply -f k8s/vs-abort-injection.yaml -n bookinfo
```

üîç Result: Jasmine sees an error like:

> `Ratings service is currently unavailable`

---

#### 2Ô∏è‚É£ Simulated Service Failure (Abort Fault)

- We then configured Istio to return a **500 Internal Server Error** for requests from Jasmine to the `ratings` service.
- Used the `abort` fault injection rule.
- **Result:** Jasmine saw a "ratings service unavailable" message. Other users continued to get normal responses.

üéØ **Why it matters:**
Fault injection helps detect cascading failures, test timeouts, and identify how resilient your services really are‚Äî**before issues hit production**.

---

---

### ‚è±Ô∏è Timeouts & üîÅ Retries in Istio: Making Microservices More Resilient

## ‚è±Ô∏è Timeouts in Istio

**Purpose:**
Prevent services from waiting indefinitely for responses from other services.

```bash
kns bookinfo
 kubectl apply -f k8s/review-02.yaml
kubectl apply -f k8s/virtual-service-all-v2.yaml

```

```bash
 kubectl apply -f k8s/vs-rating-details-delay.yaml
```

- Added a **2-second delay** to the rating and details services.

```bash
 kubectl apply -f k8s/vs-reviews-timeout.yaml
```

- Set a **0.5-second timeout** on the reviews service.
- Result: Requests timeout and users see `"Error fetching product reviews"`.

### üí° Why This Matters:

- Timeout setting makes the system **fail fast**, improving responsiveness.
- Default behavior: Istio has **no timeouts by default**, so services might hang if another is slow.

---

## üîÅ Retries in Istio

**Purpose:**
Retry failed requests automatically to improve success rates in case of **temporary issues** (e.g., network glitches).

### ‚úÖ Example Configuration:

- Retry failed calls to the rating service **up to 3 times**, within a 2-second timeout per attempt.
- After applying the retry config:

  - Errors disappeared.
  - App recovered and loaded correctly.
  - Kiali dashboard shows green (healthy communication).

```bash
 kubectl apply -f k8s/vs-ratings-retry.yaml
```

### ‚ö†Ô∏è Best Practices:

- Avoid aggressive retries. Too many retries can **overload** services and worsen failures.
- Balance is key: combine with **timeouts** and **circuit breakers**.

---

## Summary Table:

| Feature         | What It Does                                       | When to Use                          |
| --------------- | -------------------------------------------------- | ------------------------------------ |
| Fault Injection | Simulate failures or slow responses                | Test resilience, uncover hidden bugs |
| Timeout         | Limit how long a service waits for another service | Prevent hanging requests             |
| Retry           | Automatically re-send failed requests              | Handle transient failures            |

---

#### ‚è±Ô∏è Timeouts: Don‚Äôt Wait Forever

In our **BookInfo** app:

- The `productpage` service calls the `reviews` service.
- We introduced a **2-second delay** to the downstream `ratings` service.
- Then, we set a **0.5-second timeout** on the `reviews` service using Istio.

üìâ **Result:** The `reviews` service exceeded the timeout due to the downstream delay, causing the product page to fail fetching reviews.

üîç **Key insight:** By setting a timeout, we prevent services from hanging indefinitely and surface performance issues early.

#### üîÅ Retries: Handle Temporary Glitches

Timeouts prevent waiting, but what if the failure is **temporary**?

We added a retry policy to the `ratings` service:

- Istio retried failed calls up to **3 times** within a **2-second window**.
- After applying the retry config, the BookInfo app resumed normal operation despite the delay.

üìà **Result:** System recovered from transient errors without manual intervention.

#### üìä Observability

We used **Kiali** to visualize:

- Broken communication before retries were applied (red edges).
- Healthy communication paths after retry logic was introduced (green edges).

---

### üöÄ Takeaways:

- **Timeouts** help avoid cascading failures by limiting wait times.
- **Retries** help overcome temporary issues, like network blips.
- Combined, they make your services **faster**, **smarter**, and more **resilient**.

Next up: when even retries aren‚Äôt enough ‚Äî **Circuit Breaking** üßØ.

---

---

### üí° üßØ Circuit Breaking in Istio

## üîé Overview

Circuit breaking in Istio prevents a failing or overloaded service from affecting the entire system. When a service becomes unreliable (e.g., slow, error-prone), Istio can stop sending traffic to it temporarily ‚Äî giving it a chance to recover while keeping your system stable.

This is done using a **DestinationRule** that configures connection limits, request limits, and outlier detection.

---

## üìÅ Files Used

1. **`deploy_httpbin.yaml`** ‚Äì Deploys the `httpbin` sample service
2. **`fortio_client.yaml`** ‚Äì Deploys Fortio, a client to simulate traffic and load
3. **`destinationrule_circuitbreaker.yaml`** ‚Äì Defines the circuit breaking configuration for `httpbin`

---

## üõ†Ô∏è YAML Configuration Breakdown

### `destinationrule_circuitbreaker.yaml`

```yaml
apiVersion: networking.istio.io/v1
kind: DestinationRule
metadata:
  name: httpbin
spec:
  host: httpbin
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 1
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
    outlierDetection:
      consecutive5xxErrors: 1
      interval: 1s
      baseEjectionTime: 3m
      maxEjectionPercent: 100
```

üîç **Key Settings**:

- `maxConnections`: Allows only **1 TCP connection**
- `maxRequestsPerConnection`: Restricts to **1 HTTP request per connection**
- `outlierDetection`:

  - Ejects instance after **1 consecutive 5xx error**
  - Keeps it ejected for **3 minutes**
  - Monitors errors every **1 second**

---

## üöÄ Step-by-Step Deployment

### Step 1: Deploy `httpbin` Service

```bash
kubectl apply -f deploy_httpbin.yaml -n bookinfo
```

Creates:

- Deployment
- Service
- Service Account

### Step 2: Deploy Fortio Client

```bash
kubectl apply -f fortio_client.yaml -n bookinfo
```

Used for generating load and testing the circuit breaker behavior.

### Step 3: Apply DestinationRule with Circuit Breaker Config

```bash
kubectl apply -f destinationrule_circuitbreaker.yaml -n bookinfo
```

‚úÖ Confirm the rule:

```bash
kubectl get destinationrule httpbin -n bookinfo -o yaml
```

---

## üß™ Load Testing with Fortio

### Get the Fortio Pod Name

```bash
export fortio_pod=$(kubectl get pod -n bookinfo -l app=fortio -o jsonpath='{.items[0].metadata.name}')
```

### Send a Simple Request

```bash
kubectl exec -n bookinfo $fortio_pod -c fortio -- curl http://httpbin:8000/get
```

Returns `200 OK` ‚Äî service is running.

---

### Simulate Load

#### 2 Connections, 20 Requests

```bash
kubectl exec -n bookinfo $fortio_pod -c fortio -- fortio load -c 2 -n 20 http://httpbin:8000/get
```

Should still return `200 OK` ‚Äî service is healthy.

#### Repeat to Trigger Circuit Breaker

```bash
kubectl exec -n bookinfo $fortio_pod -c fortio -- fortio load -c 2 -n 20 http://httpbin:8000/get
```

Expect to start seeing some `503` responses.

#### Increase Load: 3 Connections, 30 Requests

```bash
kubectl exec -n bookinfo $fortio_pod -c fortio -- fortio load -c 3 -n 30 http://httpbin:8000/get
```

You should now see a **higher error rate** (\~43% `503` errors) ‚Äî circuit breaker is in action, ejecting the service.

---

## üß† Key Takeaways

- Istio's **DestinationRule** is used to enforce circuit breaking logic.
- Circuit breaking limits overload by:

  - Capping connections and requests
  - Automatically removing (ejecting) unhealthy instances

- This improves **resilience**, **recovery**, and **overall system stability**.

---

---

---

### üîê **Why Security Matters in Microservices**

In microservices architectures like the BookInfo app (product page, reviews, details services), traffic between services can be intercepted or tampered with by attackers. For example, a request from the product page to the reviews service could be modified, or sensitive data might be exposed.

---

### üõ°Ô∏è **How Istio Secures Your Microservices**

1. **Encryption with Mutual TLS (mTLS):**

   - Istio **automatically encrypts traffic between services** using mutual TLS.
   - This ensures that requests (e.g., product page to details) are **confidential and tamper-proof**. No one in between can spy on or alter the data.

2. **Access Control:**

   - Istio enforces **strict service-to-service authentication**.
   - For example, the product page can only communicate with authorized services like reviews or details.
   - It prevents rogue or unauthorized services from masquerading and accessing your app‚Äôs services.

3. **Service Identity and Auditing:**

   - Istio assigns a **unique identity to each service** (like a strong digital certificate).
   - This identity is used to **verify requests and maintain audit logs** ‚Äî so you know who accessed what, when, and how.
   - For example, if reviews calls ratings, Istio validates the request and logs the interaction for monitoring and security audits.

---

### üîú **Upcoming Topics**

The video series will go deeper into:

- Authentication (verifying identities)
- Authorization (permissions control)
- Certificate management (handling keys for encryption)

---

### Summary

Istio‚Äôs security features **protect your microservices communication** by encrypting traffic, verifying identities, enforcing access policies, and enabling traceability ‚Äî all essential for a secure, resilient application.

---

---

## üîê Authentication in Istio Service Mesh

### What is Authentication?

Authentication asks the question: **"Are you really who you say you are?"**
In a service mesh, this ensures only trusted services communicate with each other, preventing rogue or unauthorized services from joining the conversation.

---

### Two Main Types of Authentication in Istio Ambient Mesh

1. **Peer Authentication**

   - Ensures **mutual trust between services** sending and receiving requests.
   - Works like a handshake using **mutual TLS (mTLS)** ‚Äî both sides verify each other's identities before communicating.
   - Example: When the product page service talks to the reviews service, both verify each other‚Äôs identity with mTLS.

2. **Request Authentication**

   - Verifies **who is making the request** (the client identity).
   - Uses **JWT (JSON Web Tokens)** found in HTTP headers (typically under `Authorization: Bearer <token>`).
   - Istio checks the JWT against trusted identity providers like **Keycloak** or **Google Auth**.
   - Requests with valid tokens are allowed; invalid ones are rejected.

---

### mTLS Modes in Istio

- **Permissive Mode (default)**

  - Accepts **both encrypted (mTLS) and non-encrypted traffic**.
  - Useful when migrating services gradually to the mesh or when you don't want to block traffic immediately.

- **Strict Mode**

  - Allows **only encrypted mTLS traffic**.
  - This is the most secure mode and ensures **all service-to-service communication is encrypted** and verified.

---

---

# üîê Enforcing Peer Authentication in Istio with mTLS

## üéØ Objective

Demonstrate how **Istio PeerAuthentication** in `STRICT` mode blocks non-mTLS traffic ‚Äî ensuring that only **encrypted, secure service-to-service communication** is allowed.

---

## üß™ Step-by-Step Walkthrough

### ‚úÖ 1. Confirm BookInfo Pods Are Running

```bash
kubectl get pods -n bookinfo
```

Ensure that the **BookInfo** sample app (e.g., `productpage`, `reviews`, etc.) is up and running.

---

### üì¶ 2. Deploy a Curl Test Client in a New Namespace (`bar`)

```bash
kubectl create ns bar
kubectl apply -f curl.yaml -n bar
```

> This deploys a minimal curl container in the `bar` namespace to simulate cross-namespace traffic.

You can verify:

```bash
kubectl get pods -n bar
```

---

### üì° 3. Send a Request (Without mTLS) from `bar` to BookInfo

```bash
kubectl exec -n bar -it $(kubectl get pod -n bar -l app=curl -o jsonpath='{.items[0].metadata.name}') \
-- curl -s -o /dev/null -w "%{http_code}\n" http://productpage.bookinfo:9080
```

‚úÖ **Expected result:**
You should see `200 OK` ‚Äî this confirms that communication across namespaces **without mTLS** works by default.

---

### üîê 4. Apply Peer Authentication Policy (mTLS STRICT) to `bookinfo`

```bash
kubectl apply -f peerAuthentication.yaml
```

**`peerAuthentication.yaml`:**

```yaml
apiVersion: security.istio.io/v1
kind: PeerAuthentication
metadata:
  name: bookinfo-peer-auth
  namespace: bookinfo
spec:
  mtls:
    mode: STRICT
```

üß† This policy **enforces mTLS strictly** ‚Äî meaning BookInfo services will **reject all plaintext traffic**, including from other namespaces like `bar`.

---

### ‚ùå 5. Re-run the Curl Request (Now It Fails)

```bash
kubectl exec -n bar -it $(kubectl get pod -n bar -l app=curl -o jsonpath='{.items[0].metadata.name}') \
-- curl -s -o /dev/null -w "%{http_code}\n" http://productpage.bookinfo:9080
```

üö´ **Expected result:**
The request fails with:

```
curl: (56) Recv failure: Connection reset by peer
command terminated with exit code 56
```

üîé Explanation:

- The `bar` namespace does **not inject Istio sidecar proxies**, so its traffic is not mTLS-encrypted.
- The BookInfo services **reject the request** due to the `STRICT` mTLS mode.

---

## üåê Optional: Apply Cluster-Wide Peer Authentication

To **enforce mTLS across the entire mesh**, apply this in the `istio-system` namespace:

```yaml
apiVersion: security.istio.io/v1
kind: PeerAuthentication
metadata:
  name: default
  namespace: istio-system
spec:
  mtls:
    mode: STRICT
```

```bash
kubectl apply -f peerAuthentication-clusterwide.yaml
```

This ensures **all traffic** between services ‚Äî across **all namespaces** ‚Äî must use mTLS.

---

## üìÅ Supporting Files

### `curl.yaml`

Minimal curl client to simulate cross-namespace requests:

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: curl
---
apiVersion: v1
kind: Service
metadata:
  name: curl
  labels:
    app: curl
    service: curl
spec:
  ports:
    - port: 80
      name: http
  selector:
    app: curl
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: curl
spec:
  replicas: 1
  selector:
    matchLabels:
      app: curl
  template:
    metadata:
      labels:
        app: curl
    spec:
      terminationGracePeriodSeconds: 0
      serviceAccountName: curl
      containers:
        - name: curl
          image: curlimages/curl
          command: ['/bin/sleep', 'infinity']
          imagePullPolicy: IfNotPresent
```

---

## ‚úÖ Summary

| Scenario                            | Result    | Why                               |
| ----------------------------------- | --------- | --------------------------------- |
| Curl request without mTLS (default) | ‚úÖ 200 OK | No restrictions in place          |
| After applying mTLS STRICT policy   | ‚ùå 56     | Plaintext traffic is rejected     |
| Enable mTLS in `bar` namespace      | ‚úÖ        | If Istio sidecar is injected      |
| Cluster-wide STRICT mode            | ‚úÖ/‚ùå     | Enforces mesh-wide secure traffic |

---

### Summary

- Authentication in Istio ensures **only trusted, verified services communicate** using mTLS and JWT validation.
- **Peer Authentication** handles service-to-service identity verification (mTLS handshake).
- **Request Authentication** validates client identities via JWT tokens.
- You can configure Istio to start with permissive mode and migrate gradually to strict mode enforcing full encryption.
- Applying these policies protects your mesh from unauthorized or insecure traffic, greatly increasing security posture.

---

---

## üîê Authorization in Istio Service Mesh

### What is Authorization?

Authorization answers the question:
**"What actions or services are allowed once authenticated?"**
After confirming identities (authentication), authorization determines **what each service is permitted to do.**

---

### Use Case Example: BookInfo Application

- The **product page service** wants to call the **review service**.
- We want to **restrict product page so it can only make GET requests** to reviews, preventing any harmful operations like POST or DELETE.

Istio allows you to define **authorization policies** that specify who can call what, and which HTTP methods they are allowed to use.

---

### Layer 4 vs Layer 7 Authorization Policies

- **Layer 4 Authorization (Network Level):**
  Controls which clients (based on service accounts or IPs) can communicate with specific services or workloads.
  Example: Allow only requests from the Istio Ingress Gateway to the product page service.

- **Layer 7 Authorization (Application Level):**
  Controls **HTTP methods, paths, headers, etc.** for fine-grained access control.
  Example: Allow only GET requests from a specific client namespace or service account.

---

---

## üîê Walkthrough: Implementing Istio Authorization Policies

In this walkthrough, we‚Äôll secure access to the `productpage` service in the **Bookinfo application** using **Istio Authorization Policies**, implementing both **Layer 4 (L4)** and **Layer 7 (L7)** controls.

---

### ‚úÖ Step 1: Layer 4 (L4) Authorization Policy

#### üéØ Objective:

Restrict **any access** to the `productpage` pods **unless** it's from the **Istio Ingress Gateway's service account**.

#### üõ†Ô∏è Configuration:

```yaml
apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: productpage-viewer
  namespace: bookinfo
spec:
  selector:
    matchLabels:
      app: productpage
  action: ALLOW
  rules:
    - from:
        - source:
            principals:
              - cluster.local/ns/istio-ingress/sa/istio-ingressgateway
```

```bash
kubectl apply f k8s/L4-productpage.yaml
kubectl get pods -n bar
kubectl exec deploy/curl -n bar --curl "http://productpage.bookinfo:9080/productpage"
```

#### üîç Expected Behavior:

- ‚úÖ Access via browser or through the Ingress Gateway works as expected.
- ‚ùå Access from unauthorized sources (e.g., a `curl` pod in the `bar` namespace) is **denied**.

#### üì¶ Test Results:

- **`curl` from unauthorized pod** ‚Üí ‚ùå Access Denied
- **Browser access via Ingress** ‚Üí ‚úÖ Access Granted

---

### ‚úÖ Step 2: Layer 7 (L7) Authorization Policy

> üí° L7 policies require **Envoy Waypoint Proxy** to enforce HTTP-level rules (e.g., allowed HTTP methods).

#### üéØ Objective:

Allow **only `GET` requests** from a specific workload identity (i.e., `curl` pod in `bar` namespace).

#### üõ†Ô∏è Configuration:

```yaml
apiVersion: security.istio.io/v1
kind: AuthorizationPolicy
metadata:
  name: productpage-viewer
  namespace: bookinfo
spec:
  targetRefs:
    - kind: Service
      group: ''
      name: productpage
  action: ALLOW
  rules:
    - from:
        - source:
            principals:
              - cluster.local/ns/bar/sa/curl
      to:
        - operation:
            methods: ['GET']
```

```bash
kubectl get gateway  -n bookInfo
kubectl apply f k8s/L7-product-page.yaml
kubectl get pods -n bar
```

#### üîç Expected Behavior:

- ‚úÖ `GET` from `curl` pod (namespace `bar`) ‚Üí **Allowed**
- ‚ùå `DELETE` or other HTTP methods ‚Üí **Denied**
- ‚ùå Requests from other pods (e.g., `reviews`) ‚Üí **Denied**

#### üì¶ Test Results:

- **`curl -X DELETE` from curl pod** ‚Üí ‚ùå `Method Not Allowed`
- **`curl -X GET` from curl pod** ‚Üí ‚úÖ Success
- **Access from reviews pod** ‚Üí ‚ùå Access Denied

---

### üìå Notes:

- **Waypoint Proxy Check**: Before applying L7 policies, verify that the **Waypoint Proxy** is running and programmed (`status.programmed: true`).
- **Policy Scoping**: L4 policies operate at the TCP level (before HTTP parsing), while L7 policies enforce fine-grained controls like HTTP verbs.

---

### üß† Summary:

- üß± L4 policy secured `productpage` from all workloads **except** the Ingress Gateway.
- üì° L7 policy enforced **method-level** access (`GET` only) from a specific workload identity.
- ‚úÖ Kiali can be used to visualize and confirm that **only authorized traffic** is flowing to your services.

---

---

## üîê Certificate Management in Istio Ambient Mode

### Background: Why Manage Certificates?

Istio uses **mutual TLS (mTLS)** for secure communication between services in the mesh. This requires issuing and managing certificates to workloads so they can authenticate and encrypt traffic.

---

### How Certificate Issuance Works in Ambient Mode

1. **Workload Starts**
   When a workload (pod) starts on a node, the **CNI agent** informs the **Ztunnel** (Istio‚Äôs ambient mode sidecar proxy replacement) that a new workload is running.

2. **Ztunnel Requests Certificate**
   Ztunnel acts as the **xDS client** and connects to the Istio control plane component **Istiod** to request a certificate for the workload it represents.

3. **Istiod Verifies Request**
   Istiod checks that the workload is actually running on the node from which the request originated (to prevent spoofing).

4. **Certificate Signing**
   Once validated, Istiod signs the certificate and returns it to Ztunnel.

5. **Certificate Delivered**
   Ztunnel provides the signed certificate to the workload, enabling secure mTLS communication inside the mesh.

6. **Renewal**
   When certificates expire, **Ztunnel automatically handles certificate renewal** transparently.

---

### Generating and Installing Custom Certificates

You can generate your own **Root CA and Intermediate CA certificates** for Istio to use instead of the default ones. This is important for production-grade security and compliance.

#### Step-by-Step Process:

1. **Create a directory** to store your certificates and switch to it.
   `mkdir ca-cert`
   `cd ca-certs`
   `make -f ..k8s//tools/certs/Makefile.selfsigned.mk root-ca`
   `ls`

2. **Generate the Root CA certificate and key**

   - Using Istio‚Äôs sample Makefile or OpenSSL, generate:

     - `root-ca.conf` (OpenSSL config)
     - `root-cert.csr` (certificate signing request)
     - `root-cert.pem` (root CA certificate)
     - `root-key.pem` (root key)

3. **Generate an Intermediate CA certificate and key**

   - Use the root CA to sign the intermediate CA (e.g., named `istio-cluster`) to avoid using the root CA directly, which is a best practice.
     `make -f ../tools/certs/Makefile.selfsigned.mk istio-cluster-cacerts`
     `cd istio-cluster`

4. **Create a Kubernetes secret in the `istio-system` namespace** with these certificates:

   ```bash
   kubectl create namespace istio-system
   kubectl create secret generic cacerts -n istio-system \
     --from-file=root-cert.pem=path/to/root-cert.pem \
     --from-file=root-key.pem=path/to/root-key.pem \
     --from-file=cert-chain.pem=path/to/intermediate-cert.pem \
     --from-file=key.pem=path/to/intermediate-key.pem
   ```

5. **Install or reinstall Istio** with these certificates.

   - Either delete your existing Istio installation and redeploy, or start a fresh cluster and install Istio.
   - Use a script or Istioctl to deploy Istio and your sample apps (like Bookinfo).
     `./install.sh`

6. **Label your application namespaces** with `istio.io/dataplane-mode=ambient` to enable ambient mode proxying.
   `kubectl get pods -n bookinfo`
   `kubectl label namespace bookInfo istio.io/dataplane-mode=ambient`
   `curl http://localhost:80/productpage`

---

### Verifying Certificates in Use

- Check the **Ztunnel pod** which holds the certificates in ambient mode.

`kubectl get pods -n istio-system`

- Use Istioctl to inspect certificates:

  ```bash
  istioctl ztunnel-config certificate <ztunnel-pod-name> -n <namespace>

  or

    istioctl ztunnel-config certificate <ztunnel-pod-name>.istio-system>
  ```

- Extract and compare the certificates inside Ztunnel with the certificates you created locally using:

  ```bash
  istioctl ztunnel-config certificate ztunnel-h8581.istio-system -o json jq -r '.[0].certChain[0].pem' | base64 -d openssl x509 -text - nout > ztunnel-cert;crt.txt
  ```

```
x509 -in ca-certs/istio-cluster/root-cert.pem > root-cert.crt.txt

diff -s root-cert.txt ztunnel-cert.crt.txt
diff -s ca-cert.txt ztunnel.crt.txt
```

compare

- Matching files confirm that Istio is using your custom Root CA and certificates correctly.

---

### Important Notes for Production

- The manual certificate generation process is fine for demos and labs.
- For production, consider using **robust external certificate authorities** like **HashiCorp Vault** or a managed CA solution for secure, automated certificate lifecycle management.

---

### Summary

| Step                        | Description                                       |
| --------------------------- | ------------------------------------------------- |
| Workload starts             | CNI informs Ztunnel of new workload               |
| Ztunnel requests cert       | Connects to Istiod, authenticates node & workload |
| Istiod signs & returns cert | Signs certificate & sends back                    |
| Ztunnel delivers cert       | Provides cert to workload for mTLS                |
| Certificate renewal         | Ztunnel auto-renews expired certs                 |
| Custom cert generation      | Generate root and intermediate CA certs           |
| Create Kubernetes secret    | Store certs in `istio-system` namespace           |
| Deploy Istio with certs     | Fresh install or reinstall using your certs       |
| Verify cert usage           | Use `istioctl` and `diff` to confirm certs        |

--- -->

---

## üìä Introduction to Monitoring in Istio

### Why Monitoring Matters

As your application scales, things can start to go wrong: pages might load slowly, services may fail, or unexpected errors could occur. When this happens, the key challenge is understanding **what‚Äôs causing the problem**. For example:

- Is the **rating service** too slow?
- Did the **review service crash**?
- Or is it something else entirely?

---

### What Istio Brings to Observability

Istio helps by providing **deep visibility into your application‚Äôs behavior** ‚Äî often called **observability**. This means you get clear insights into how your services are performing and communicating behind the scenes.

---

### How Istio Collects Monitoring Data in Ambient Mode

In an **ambient mesh**, Istio collects telemetry data mainly from two components:

- **Ztunnel proxies** (which handle the workload-level communication)
- **Waypoint proxies** (which handle ingress/egress traffic)

---

### The Three Pillars of Istio Monitoring Data

Istio breaks down its monitoring data into three key categories:

| Data Type              | Description                                                                 | Use Cases                                    |
| ---------------------- | --------------------------------------------------------------------------- | -------------------------------------------- |
| **Metrics**            | Quantitative data like request counts, latencies, error rates               | Overall health & performance tracking        |
| **Access Logs**        | Logs of every request with info about source, destination, and status       | Troubleshooting, auditing, forensic analysis |
| **Distributed Traces** | Visual maps of how requests travel through services, showing latency points | Pinpoint bottlenecks, latency, or failures   |

---

### Why This Matters

With Istio‚Äôs monitoring tools, you can:

- **Catch issues early** before users notice problems
- **Fix problems quickly** with detailed diagnostics
- **Keep your app running smoothly** by continuously observing service health and interactions

---

---

## üìà Visualizing Metrics with Prometheus and Grafana in Istio

### Why Visualize Metrics?

Visualizing metrics helps you understand what's happening with your services **in real time** so you can quickly spot performance issues and fix them before they impact users.

---

### The Tools: Prometheus and Grafana

- **Prometheus:**
  An open-source monitoring tool that **collects and stores metrics** from your services. It gathers data such as:

  - Traffic volume
  - Error counts
  - Response times

- **Grafana:**
  A powerful visualization tool that takes data from Prometheus and turns it into **interactive graphs and dashboards**, making it easier to interpret metrics visually.

---

### Key Istio Metrics to Monitor

Istio provides essential metrics to track the health and performance of your services:

| Metric     | What It Shows                      | Why It Matters           |
| ---------- | ---------------------------------- | ------------------------ |
| Latency    | How quickly services respond       | Identify slowdowns       |
| Traffic    | Volume of requests handled         | Understand demand & load |
| Errors     | Frequency of failures or errors    | Detect problems          |
| Saturation | How close services are to overload | Prevent service crashes  |

Together, these metrics give you a **clear picture of your system‚Äôs performance** and where you may need to act.

---

### Setting Up Prometheus

1. **Check if Prometheus is running:**

   ```bash
   kubectl get svc -n istio-system prometheus
   ```

   If it‚Äôs not running, install it using the provided manifests (`prometheus.yaml`).

   kubectl apply -f prometheus.yaml -n istio-system

2. **Generate traffic:**
   Run a command to generate load on your BookInfo app, so metrics start flowing.

   ```bash
   for i in $(seq 1 100); do
   curl -s http://localhost/productpage
   done

   ```

3. **Access Prometheus UI:**
   Use Istioctl to open Prometheus:

   ```bash
   istioctl dashboard prometheus
   ```

````

4. **Query metrics:**
   Example queries include:

   - Total requests:

     ```
     istio_requests_total
     ```

   - Requests to the product page:

     ```
     istio_requests_total{destination_service="productpage.bookinfo.svc.cluster.local"}
     ```

   - Requests to reviews service version 3:

     ```
       istio_requests_total{destination_service="reviews.bookinfo.svc.cluster.local",destination_version="v3"}
     ```

   - Request rate over 5 minutes in products page:

     ```
     rate(istio_requests_total{destination_service="productpage.*", response_code="200"}[5m])
     ```

---

### Setting Up Grafana

1. **Install Grafana:**
   Apply the manifest to the `istio-system` namespace:

   ```bash
   kubectl apply -f grafana.yaml -n istio-system
   ```

2. **Open Grafana Dashboard:**
   Use Istioctl to open Grafana:

   ```bash
   istioctl dashboard grafana
   ```

3. **Explore Prebuilt Dashboards:**
   Grafana includes several dashboards out of the box:

   - **Control Plane Dashboard**
   - **Service Dashboard**
   - **Workload Dashboard**
   - **Istio Service Dashboard** (deep dive into individual services)

---

### Summary

- Prometheus **collects** detailed metrics from your Istio service mesh.
- Grafana **visualizes** these metrics, giving you intuitive, real-time insight.
- Together, they provide a powerful monitoring solution to keep your Istio mesh healthy and performant.

---

---

## üîç Distributed Tracing with Jaeger in Istio

### What Is Distributed Tracing?

- While **metrics** provide an overall picture of how your services are performing, **distributed tracing** lets you **follow individual requests** step-by-step as they flow through your service mesh.
- Imagine tracing a package delivery ‚Äî you can see every stop it makes and how long it spends at each stage.
- This helps you pinpoint exactly where slowdowns, errors, or failures occur within your microservices.

---

### Why Use Jaeger?

- **Jaeger** is a popular open-source tool for distributed tracing.
- It acts like a GPS for your application, showing the full path of each request as it moves across your services.
- Istio supports multiple tracing backends (Jaeger, Zipkin, Datadog, etc.), but Jaeger is often used because of its integration and features.

---

### How to Enable Tracing with Jaeger in Istio

1. **Enable tracing in Istio's mesh config:**

   - Set `enableTracing: true` in the mesh config to start collecting trace data.
   - Clean up old tracing configs by setting tracing to the MT (multi-tenant) config.
   - Configure the tracing provider in the extension provider section to point to Jaeger via OpenTelemetry.


2. **Enable telemetry:**

   - Make sure telemetry is enabled (`enabled: true`) so Istio collects both metrics and tracing data for full visibility.

3. **Apply configuration:**

   - If you installed Istio via Helm, apply these changes using a `helm upgrade` with the updated values file.
   - Confirm Istio pods (like `istiod`) are running before upgrading.

4. **Set up the Jaeger collector:**

   - Deploy Jaeger to listen for incoming trace data from Istio.
   - Modify `telemetry.yaml` to send all traces to the Jaeger collector.



```bash
kubectl get pods -n istio-system  # to confirm is istiod is running

helm upgrade istiod istio/istiod -n istio-system --set profile=ambient --wait --values k8s/monitoring/tracing/tracing-values.yaml

kubectl apply -f k8s/monitoring//tracing/telemetry.yaml

```

   ```bash
   for i in $(seq 1 100); do
   curl -s http://localhost/productpage
   done

   ```

Apply delay and tracse the delay with jaeger

   ```bash
   kubectl apply -f  k8s/monitoring/tracing/delay.yaml -n bookinfo
   ```



      ```bash
   for i in $(seq 1 100); do
   curl -s http://localhost/productpage
   done

   ```
---

### Using Jaeger to Visualize Traces

- **Generate traffic** on your application to create trace data.
- Open the Jaeger UI with:

  ```bash
  istioctl dashboard jaeger
  ```

- In the **Search tab**:

  - Select the service you want to view traces for (e.g., `istio-ingressgateway`).
  - Add filters like tags or operation types if needed.
  - Set the number of traces to display (e.g., 50 or 100).

- View individual traces, which include **spans** showing each step the request took across services.
- Inspect timings and errors within the trace to identify slow or failing parts.

---

### Example: Introducing Latency and Observing Effects

- You can simulate delays (like adding a 10-second delay in the `details` service) by creating a **Virtual Service** that injects latency.
- After applying the delay and generating traffic, you can observe:

  - Red error indicators in tools like **Kiali** on the affected services.
  - Errors and increased latency reflected in Jaeger traces, with the affected spans marked accordingly.

This demonstrates how distributed tracing helps you quickly identify and diagnose service-level issues.

---

### Summary

- Distributed tracing lets you **follow each request‚Äôs journey** across your microservices.
- Jaeger provides a rich, interactive UI to explore these traces.
- Enabling tracing in Istio and setting up Jaeger gives you **deep insight** to find and fix issues quickly.
- Combined with other observability tools (metrics, logs), tracing completes your visibility into how your service mesh performs.

---

---

## üîç Visualizing Your Service Mesh with Kiali

### What is Kiali?

- Kiali is a powerful **observability tool** designed specifically for **service mesh** environments like Istio.
- It helps you **monitor, visualize, and troubleshoot** your microservices by providing real-time insights into how services interact within your mesh.
- Beyond simple visualization, Kiali also checks for **configuration errors** and displays health status for services and namespaces.

---

### How to Access Kiali

- You can access the Kiali dashboard by running the following command to open a local port forward to your Kiali instance:

  ```bash
  istioctl dashboard kiali
  ```

- This opens a web UI where you can explore your mesh data visually.

---

### Kiali Overview Page

- The first screen you see gives you an **overview of all namespaces and applications** deployed in your mesh.
- For each namespace, Kiali displays:

  - The list of deployed applications and services.
  - The **health status** indicators:

    - **Green:** Everything is healthy.
    - **Yellow or Red:** Issues detected, such as failed requests or misconfigurations.

- You can click on a namespace or service to drill down for more details.

---

### Traffic Graph ‚Äî Visualizing Service Interactions

- The **traffic graph** is one of Kiali‚Äôs most useful features.
- It shows a **graphical representation of all services** and how they communicate with each other.
- To see live traffic data:

  - Generate traffic on your application (e.g., by running load or test commands).
  - Refresh the Kiali dashboard to see updated graphs.

- The graph illustrates:

  - Services (nodes) like `product page`, `reviews`, `ratings`, etc.
  - Connections between services (edges) representing traffic flow.
  - Incoming traffic through `istio-ingressgateway`.
  - Different versions of services if deployed.

---

### Inspecting Metrics on the Traffic Graph

- Hovering or clicking on connections between services reveals key metrics:

  - Request rates.
  - Success and error percentages.
  - Latency or other performance indicators.

- This helps quickly identify bottlenecks or failing connections.

---

### Detailed Service View

- Clicking on a service node (e.g., `product page`) opens a detailed view.
- Here, you can explore:

  - Inbound and outbound traffic metrics.
  - TCP metrics like TCP opened, TCP closed, and TCP received.
  - Other relevant service health and performance metrics.

- You can customize and filter metrics as needed.

---

### Configuration Validation

- Kiali also helps detect **configuration errors**.
- Example: If you define a **destination rule** referencing a non-existent service version (like version `v4` for reviews which isn‚Äôt deployed), Kiali will show an error.
- This immediate feedback helps avoid misconfigurations before applying them.
- Fixing the config (e.g., removing the invalid version subset) removes the error warning.

---

### Filtering and Exploring Resources

- You can filter views by resource types such as:

  - Authorization policies.
  - Destination rules.
  - Virtual services.

- This makes it easier to manage complex configurations in your mesh.

---

### Security Insights with Mutual TLS (mTLS)

- In the traffic graph, you can enable the **Security tab** to see:

  - Which services are communicating using **mutual TLS (mTLS)**.
  - This visual overlay helps verify secure communication within the mesh.

---

### Additional Features

- **Waypoint Proxy view:** See detailed internal communication within your mesh.
- Kiali is more than a visualization tool; it‚Äôs a **full observability platform** with extensive capabilities for:

  - Monitoring.
  - Troubleshooting.
  - Security validation.
  - Configuration management.

---

### Summary

- **Kiali helps you visualize and monitor your Istio service mesh in real-time.**
- It provides a graphical map of service communication with rich metrics.
- Detects errors in your configuration before they impact your system.
- Supports filtering by resource type and viewing security settings like mTLS.
- The more you use Kiali, the easier it becomes to manage and troubleshoot complex microservice architectures.

---
````

delete profile

```bash
minikube stop -p istio-demo
minikube delete -p istio-demo
# minikube pause -p istio-demo
# minikube unpause -b istio-demo
# kubectl rollout restart deployment -n bookinfo
# kubectl rollout restart deployment -n istio-system
# kubectl rollout restart daemonset/istio-cni-node -n istio-system
# kubectl rollout restart deployment/coredns -n kube-system

```
